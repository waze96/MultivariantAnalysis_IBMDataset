---
output:
  word_document: default
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

# Retrieve the data saved AFTER the profiling practice, this means data already cleaned

```{r, echo=FALSE}

library(GGally)
library(cluster)
library(ggplot2)

load("./Data/df_preprocessed_IBM_Employees.Rdata") 
names(df) 

dim(df)
summary(df)

# Remove usless variables.
df<-subset(df, select = -c(DailyRate,HourlyRate,MonthlyRate,AgeToJubilation,TrainingTimesLastYear,DistanceFromHome))

dcon<-df[!sapply(df, is.factor)]

```

# Transform and Normalize

```{r}

df_trans <- dcon

hist(dcon$Age) # normalize(scale)
hist(scale(dcon$Age))

hist(dcon$MonthlyIncome, breaks = 20) # log?
df_trans$MonthlyIncome <- log(dcon$MonthlyIncome)
hist(df_trans$MonthlyIncome, breaks = 20) # create quantiles ?

hist(dcon$NumCompaniesWorked) 

hist(dcon$PercentSalaryHike) 

hist(dcon$TotalWorkingYears) # create quantiles ? 

hist(dcon$YearsAtCompany) # log 
hist(log(dcon$YearsAtCompany))
df_trans$YearsAtCompany <- log(dcon$YearsAtCompany+1)

hist(dcon$SalaryHikePerYear) # log 
hist(log(dcon$SalaryHikePerYear))
df_trans$SalaryHikePerYear <- log(dcon$SalaryHikePerYear)

hist(dcon$AverageYearsCompany) # log 
hist(log(dcon$AverageYearsCompany))
df_trans$AverageYearsCompany <- log(dcon$AverageYearsCompany)

df_norm<-df_trans

range01 <- function(x){(x-min(x))/(max(x)-min(x))}
for(i in colnames(df_trans)){ df_norm[,i] <- range01(df_trans[,i]) }

boxplot(df_norm)

```

# CLUSTERING

```{r, echo=FALSE}

df_norm[c(1:5),]
dist(df_norm[c(1:5),])
# HIERARCHICAL CLUSTERING (Euclidean distance)
d<-dist(df_norm) 
h1<- hclust(d,method="ward.D")

options(max.print=2000)
h1$height # height of the tree branches
plot(h1)
rect.hclust(h1, h=45.23490403,border="green") # 6 clusters
rect.hclust(h1, h=50.06270659,border="blue") # 4 clusters
rect.hclust(h1, h=53.16115400,border="red") # 3 clusters
rect.hclust(h1, h=76.99302916,border="orange") # 3 clusters
rect.hclust(h1, h=186.14590016,border="purple") # 2 clusters


```

# MEANS per CLUSTER

```{r, echo=FALSE}
# WHERE ARE THER THE LEAPS? WHERE WILL YOU CUT THE DENDOGRAM?, HOW MANY CLASSES WILL YOU OBTAIN?
nc = 6
c1<-cutree(h1,nc)
df$cluster<-c1

cdg <- aggregate(as.data.frame(dcon),list(c1),mean) 
cdg

dcon$cluster<-as.factor(c1)

table(c1) 
# LETS SEE THE PARTITION VISUALLY
#ggplot(df, aes(MonthlyIncome, Age, color=cluster, shape=Attrition))+
#   geom_point()


ggpairs(dcon, columns=c(1:4,12), aes(color=cluster, alpha=0.5), progress=F)
ggpairs(dcon, columns=c(5:8,12), aes(color=cluster, alpha=0.5), progress=F)
ggpairs(dcon, columns=c(9:12), aes(color=cluster, alpha=0.5),progress=F)


```

# Mixed variables

```{r}
#move to Gower mixed distance to deal 
#simoultaneously with numerical and qualitative data
dcategoriques<-df[sapply(df, is.factor)]
#dcategoriques<-subset(dcategoriques, select = -c(DistanceFromHome,Education, EducationField, JobLevel, JobRole))
dcategoriques<-subset(dcategoriques, select = -c(Attrition))
names(dcategoriques)

#join the dcategoriques with the filtered df_norm into a new df ->df_join
colnames(df_norm)

df_join <- df_norm

for(i in colnames(dcategoriques)){ df_join[,i] <- dcategoriques[,i] }
colnames(df_join)

#dissimilarity matrix

dissimMatrix <- daisy(df_join, metric = "gower", stand=TRUE)
distMatrix<-dissimMatrix^2

h1<-hclust(distMatrix,method="ward.D")

options(max.print=2000)
h1$height # height of the tree branches
plot(h1)
rect.hclust(h1, h=4.718142549,border="green") # 6 clusters
rect.hclust(h1, h=5.623154687,border="blue") # 6 clusters
rect.hclust(h1, h=9.018713628,border="blue") # 3 clusters
rect.hclust(h1, h=17.808008541,border="red") # 2 clusters
rect.hclust(h1, h=28.610542954,border="orange") # 2 clusters

plot(h1) 
c2<-cutree(h1,5)
# Add cluster classification + Attrtion after clustering
df_join$clust<-as.factor(c2)
df_join$Attrition<-df$Attrition

#Attrition
boxplot(df_join$Attrition~df_join$clust)
table(df_join$Attrition,df_join$clust)

#MonthlyIncome 
boxplot(df_join$MonthlyIncome~c2, horizontal=TRUE)


ggpairs(df_pro, columns = c(2,1:4), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,5:7), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,8:10), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,11:13), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,14:17), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,18:21), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,22:25), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,26:29), aes(color = clust, alpha = 0.5),progress = FALSE)
ggpairs(df_pro, columns = c(2,30:32), aes(color = clust, alpha = 0.5),progress = FALSE)


ggpairs(df_pro, columns = c(2,4), aes(color = clust, alpha = 0.5),progress = FALSE)

table(df_pro[df_pro$clust==1,]$Attrition)
table(df_pro[df_pro$clust==2,]$Attrition)
table(df_pro[df_pro$clust==3,]$Attrition)

table(df_pro[df_pro$clust==1,]$Department)
table(df_pro[df_pro$clust==2,]$Department)
table(df_pro[df_pro$clust==3,]$Department)


pairs(dcon[,1:7], col=c2)

plot(RatiFin,Estalvi,col=c2,main="Clustering of credit data in 4
classes") legend("topright",levels(as.factor(c2)),pch=1,col=c(1:4),
cex=0.6)

cdg \<- aggregate(as.data.frame(dcon),list(c2),mean) cdg

plot(Edad, Gastos, col= c2) points(cdg[,4],cdg[,5],pch=16,col="orange")
text(cdg[,4],cdg[,5], labels=cdg[,1], pos=2, font=2, cex=0.7,
col="orange")

potencials\<-c(3,4,6,7,10,11) pairs(dcon[,potencials],col=c2)

#Profiling plots
```

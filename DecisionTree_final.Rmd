---
title: "Decision Tree"
author: ""
date: "2022-11-27"
output: html_document
---

```{r include=FALSE}

# Clear plots from the R plots view:
if(!is.null(dev.list())) dev.off()

# Clean workspace - No variables at the current workspace
rm(list=ls())
```

```{r, setup, include=FALSE, echo=FALSE}

requiredPackages <- c("ggplot2","rapportools","plyr","cowplot", "ggpubr", "corrplot", "corrplot", "mlbench", "caret", "FactoMineR", "datasets", "caTools", "party", "dplyr", "magrittr", "rpart", "rpart.plot", "pROC")
packages.check <- lapply(requiredPackages, FUN = function(x) {
  if(!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
```

```{r, echo=TRUE}
df <- read.csv("C:/Users/ibrah/Desktop/FIB/MVA/Project/data_mva.csv")
#df <- read.csv("~/Documents/UPC/1Q/MultivariateAnalysis_MVVA/Labs/D1/WA_Fn-UseC_-HR-Employee-Attrition.csv")

#df <- read.csv("C:/Users/matteo/Desktop/Barcelone_Cours/MVA/DM/WA_Fn-UseC_-HR-Employee-Attrition.csv")
```


# Preprocessing

```{r, echo=False}

df$Attrition=as.factor(df$Attrition)

df$BusinessTravel=as.factor(df$BusinessTravel)

df$Department=as.factor(df$Department)

# Reduce number of levels from 29 to 7
df$DistanceFromHome=as.factor(df$DistanceFromHome)
levels(df$DistanceFromHome) <- c("1", "1", "2", "2", "2", "2", "3", "3", "3", "3", "4", "4", "4", "4", "4", "5", "5", "5", "5", "5", "5", "5", "6", "6", "6", "6", "6", "7", "7")

df$Education=as.factor(df$Education)
levels(df$Education) <- c('Below College', 'College', 'Bachelor', 'Master', 'Doctor')

df$EducationField=as.factor(df$EducationField)

df$EnvironmentSatisfaction=as.factor(df$EnvironmentSatisfaction)
levels(df$EnvironmentSatisfaction) <- c('Low', 'Medium', 'High', 'Very High')

df$Gender=as.factor(df$Gender)

df$JobInvolvement=as.factor(df$JobInvolvement)
levels(df$JobInvolvement) <- c('Low', 'Medium', 'High', 'Very High')

df$JobLevel=as.factor(df$JobLevel)
levels(df$JobLevel) <- c('Intern', 'Junior', 'Senior', 'Manager', 'Director')

# Reduce number of levels from 9 to 7
df$JobRole=as.factor(df$JobRole)
levels(df$JobRole) <- c("Representatives", "H.R.", "Lab. Tech.", "Manager", "Directors", "Directors", "Research Sci.", "Sales Executive", "Representatives")

df$JobSatisfaction=as.factor(df$JobSatisfaction)
levels(df$JobSatisfaction) <- c('Low', 'Medium', 'High', 'Very High')

df$MaritalStatus=as.factor(df$MaritalStatus)

df$Over18=as.factor(df$Over18)

df$OverTime=as.factor(df$OverTime)

df$PerformanceRating=factor(df$PerformanceRating, levels = c(1, 2, 3, 4))
levels(df$PerformanceRating) <- c('Low', 'Good', 'Excellent', 'Outstanding')

df$RelationshipSatisfaction=as.factor(df$RelationshipSatisfaction)
levels(df$RelationshipSatisfaction) <- c('Low', 'Medium', 'High', 'Very High')

df$StockOptionLevel=as.factor(df$StockOptionLevel)
levels(df$StockOptionLevel) <- c('No', 'Few', 'Medium', 'High')

df$WorkLifeBalance=as.factor(df$WorkLifeBalance)
levels(df$WorkLifeBalance) <- c('Bad', 'Good', 'Better', 'Best')

df_clean <- df[,c(1:3,5:8,11,12,14:21,23:26,28:35)] #remove daily rate, hourly rate, employee count, employee number, over18, standard hours

#View(df_clean)
str(df_clean)

```


# Splitting dataset into train and test data

```{r}

set.seed(999)
ind <- sample(2, nrow(df_clean), replace = T, prob = c(0.8, 0.2))
train <- df_clean[ind == 1,]
test <- df_clean[ind == 2,]

RealAttritionValuesFromTestSet = test$Attrition
test <- test[,-2] #to remove attrition from test data
```


# Modelling many model with package caret

```{r message=FALSE, warning=FALSE}

model <- train(Attrition~., data = train,
               method = "rpart",
               tuneLength = 20, 
               maxdepth = 25, 
               metric = "Kappa", # better metrics for unbalanced dataset
               maximize = TRUE,
               cp = 0,
               #tuneGrid = tuneGrid,
               trControl = trainControl(method = "cv",
                                        number = 3,
                                        sampling = "smote", # try with down | up | rose | smote : smote seems be the best
                                        selectionFunction = "best"
                                        )) 
ggplot(model)
rpart.plot(model$finalModel)

```


# Evaluate models

```{r}

p1 <- predict(model, test, type = 'prob')
p1 <- p1[,2]
r <- multiclass.roc(RealAttritionValuesFromTestSet, p1, percent = TRUE)
roc <- r[['rocs']]
r1 <- roc[[1]]
plot.roc(r1,print.auc=TRUE,
         auc.polygon=TRUE,
         grid=c(0.1, 0.2),
         grid.col=c("green", "red"),
         max.auc.polygon=TRUE,
         auc.polygon.col="lightblue",
         print.thres=TRUE,
         main= 'ROC Curve')

p <- predict(model, train)
confusionMatrix(p, train$Attrition, positive="Yes")

p2 <- predict(model, test)
confusionMatrix(p2, RealAttritionValuesFromTestSet, positive="Yes")

varImp(model)

# see 
# - Sensitivity (good yes / total yes)
# - Balanced Accuracy
```







```{r}


####Modelling with RandomForest
model <- train(Attrition~., data = train,
               method = "rf",
               tuneLength = 20, 
               maxdepth = 5, 
               metric = "Kappa", # better metrics for unbalanced dataset
               maximize = TRUE,
               cp = 0,
               #tuneGrid = tuneGrid,
               trControl = trainControl(method = "cv",
                                        number = 3,
                                        sampling = "smote", # try with down | up | rose | smote : smote seems be the best
                                        selectionFunction = "best"
                                        )) 
ggplot(model)
rpart.plot(model$finalModel)
p1 <- predict(model, test, type = 'prob')
p1 <- p1[,2]
r <- multiclass.roc(RealAttritionValuesFromTestSet, p1, percent = TRUE)
roc <- r[['rocs']]
r1 <- roc[[1]]
plot.roc(r1,print.auc=TRUE,
         auc.polygon=TRUE,
         grid=c(0.1, 0.2),
         grid.col=c("green", "red"),
         max.auc.polygon=TRUE,
         auc.polygon.col="lightblue",
         print.thres=TRUE,
         main= 'ROC Curve')

p <- predict(model, train)
confusionMatrix(p, train$Attrition, positive="Yes")

p2 <- predict(model, test)
confusionMatrix(p2, RealAttritionValuesFromTestSet, positive="Yes")



```
















